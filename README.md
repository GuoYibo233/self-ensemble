# Self-Ensemble with FlexAttention

æœ¬ä»“åº“å®ç°äº†å¤šç§è‡ªé›†æˆï¼ˆself-ensembleï¼‰æ–‡æœ¬ç”Ÿæˆæ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºFlexAttentionçš„é«˜æ•ˆæ³¨æ„åŠ›çº§èåˆæ–¹æ³•ã€‚

## ğŸ“– æ–‡æ¡£å¯¼èˆª

**é¦–æ¬¡ä½¿ç”¨è¯·é˜…è¯»:**

1. **[GENERATE_README.md](GENERATE_README.md)** - æ‰€æœ‰ç”Ÿæˆè„šæœ¬çš„è¯¦ç»†è¯´æ˜å’ŒåŒºåˆ«ï¼ˆä¸­æ–‡ï¼‰
2. **[archived/docs/](archived/docs/)** - å®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£ï¼ˆå·²å½’æ¡£ï¼‰

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

æœ¬ä»“åº“æä¾›**å››ç§ç”Ÿæˆæ–¹æ³•**ï¼Œé€‚ç”¨äºä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š

1. **Baselineç”Ÿæˆ** - åŸºå‡†å¯¹æ¯”æ–¹æ³•ï¼ˆorigin/per_promptï¼‰
2. **Originalé›†æˆ** - ä¼ ç»Ÿlogitçº§èåˆï¼ˆmax/avg/weightedï¼‰
3. **FlexAttentioné›†æˆ** - é«˜æ•ˆçš„attentionçº§èåˆï¼ˆWebQAï¼‰
4. **MyriadLAMAé›†æˆ** - é’ˆå¯¹å¡«ç©ºä»»åŠ¡ä¼˜åŒ–çš„FlexAttention

### æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | èåˆæ–¹å¼ | æ•ˆç‡ | é€‚ç”¨åœºæ™¯ |
|------|---------|------|---------|
| Baseline | æ— èåˆ | æœ€å¿« | å¯¹æ¯”åŸºå‡† |
| Original | Logitçº§ | æ ‡å‡† (NÃ—å‰å‘) | ç ”ç©¶ä¸åŒèåˆç­–ç•¥ |
| **FlexAttention** | **Attentionçº§** | **æœ€é«˜æ•ˆ (1Ã—å‰å‘)** | **WebQAé—®ç­”ï¼ˆæ¨èï¼‰** |
| MyriadLAMA | Attentionçº§ | æœ€é«˜æ•ˆ (1Ã—å‰å‘) | å¡«ç©ºä»»åŠ¡ |

è¯¦ç»†å¯¹æ¯”è¯·å‚è€ƒï¼š[GENERATE_README.md](GENERATE_README.md)

## ğŸ”§ ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.10+
- PyTorch 2.5+ æˆ– nightlyï¼ˆFlexAttentionéœ€è¦ï¼‰
- NVIDIA GPU with CUDA
- Conda/Miniconda

### å¿«é€Ÿå®‰è£…

```bash
# 1. åˆ›å»ºcondaç¯å¢ƒ
conda env create -f environment.yml
conda activate flexattention

# æˆ–ä½¿ç”¨Linuxç‰¹å®šç¯å¢ƒï¼ˆUbuntu 22.04+ï¼‰
conda env create -f environment_linux.yml
conda activate self-ensemble-debug

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt
python -m spacy download en_core_web_lg

# 3. å®‰è£…PyTorch nightlyï¼ˆæ”¯æŒFlexAttentionï¼‰
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121
```

è¯¦ç»†é…ç½®è¯´æ˜ï¼š[archived/docs/QUICKSTART.md](archived/docs/QUICKSTART.md)

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ä¸€ï¼šäº¤äº’å¼è¿è¡Œï¼ˆæ¨èï¼‰

```bash
python src/run_interactive.py
```

äº¤äº’å¼ç•Œé¢ä¼šå¼•å¯¼æ‚¨é€‰æ‹©ï¼š
- ç”Ÿæˆç±»å‹ï¼ˆbaseline/original/flex_attention/myriadlamaï¼‰
- æ•°æ®é›†ï¼ˆwebqa/myriadlamaï¼‰
- æ¨¡å‹
- æ–¹æ³•ç‰¹å®šå‚æ•°

### æ–¹å¼äºŒï¼šç›´æ¥è¿è¡Œ

```bash
# BaselineåŸºå‡†ç”Ÿæˆ
python src/generate_baseline.py --method origin --dataset webqa --model llama3.2_3b_it

# Originalé›†æˆæ–¹æ³•
python src/generate_original.py --method max --dataset webqa --model llama3.2_3b_it --num_ensemble 6

# FlexAttentioné›†æˆï¼ˆæ¨èï¼‰
python src/generate_flex_attention.py --dataset webqa --model llama3.2_3b_it --num_paraphrases 5

# MyriadLAMAå¡«ç©ºä»»åŠ¡
python src/generate_myriadlama.py --dataset myriadlama --model llama3.2_3b_it --num_paraphrases 5
```

### å¿«é€Ÿæµ‹è¯•

```bash
# é™åˆ¶æ ·æœ¬æ•°é‡ï¼Œå¿«é€Ÿæµ‹è¯•
python src/generate_flex_attention.py \
    --dataset webqa \
    --model llama3.2_3b_it \
    --num_paraphrases 5 \
    --max_samples 100
```

**å®Œæ•´ä½¿ç”¨æŒ‡å—**: [GENERATE_README.md](GENERATE_README.md)

## ğŸ“ ä»“åº“ç»“æ„

```
.
â”œâ”€â”€ src/                           # æ ¸å¿ƒç”Ÿæˆè„šæœ¬
â”‚   â”œâ”€â”€ core/                      # å…±äº«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ constants.py           # æ¨¡å‹é…ç½®
â”‚   â”‚   â”œâ”€â”€ dataset.py             # æ•°æ®é›†åŠ è½½
â”‚   â”‚   â”œâ”€â”€ paraphrase.py          # é‡Šä¹‰ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ confidence.py          # ç½®ä¿¡åº¦è®¡ç®—
â”‚   â”‚   â”œâ”€â”€ utils.py               # å·¥å…·å‡½æ•°
â”‚   â”‚   â””â”€â”€ interactive.py         # äº¤äº’å¼è¾“å…¥
â”‚   â”‚
â”‚   â”œâ”€â”€ generate_baseline.py      # åŸºå‡†ç”Ÿæˆ
â”‚   â”œâ”€â”€ generate_original.py      # Originalé›†æˆ
â”‚   â”œâ”€â”€ generate_flex_attention.py # FlexAttentioné›†æˆ
â”‚   â”œâ”€â”€ generate_myriadlama.py    # MyriadLAMAé›†æˆ
â”‚   â””â”€â”€ run_interactive.py        # äº¤äº’å¼è¿è¡Œå™¨
â”‚
â”œâ”€â”€ mask_visualization.py         # Maskå¯è§†åŒ–
â”œâ”€â”€ requirements.txt              # Pythonä¾èµ–
â”œâ”€â”€ environment.yml               # Condaç¯å¢ƒ
â”œâ”€â”€ environment_linux.yml         # Linuxç¯å¢ƒ
â”‚
â”œâ”€â”€ GENERATE_README.md            # ç”Ÿæˆè„šæœ¬è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ README.md                     # æœ¬æ–‡ä»¶
â”‚
â””â”€â”€ archived/                     # å½’æ¡£æ–‡ä»¶
    â”œâ”€â”€ docs/                     # è¯¦ç»†æ–‡æ¡£
    â”œâ”€â”€ tests/                    # æµ‹è¯•æ–‡ä»¶
    â”œâ”€â”€ tools/                    # å·¥å…·è„šæœ¬
    â”œâ”€â”€ analysis/                 # åˆ†æå·¥å…·
    â”œâ”€â”€ notebooks/                # Jupyterç¬”è®°æœ¬
    â””â”€â”€ ...                       # å…¶ä»–å½’æ¡£å†…å®¹
```

## ğŸ’¡ å¸¸è§é—®é¢˜

### FlexAttentionä¸å¯ç”¨

```bash
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121
```

### CUDAå†…å­˜ä¸è¶³

```bash
python src/generate_flex_attention.py --device cpu
```

### æ•°æ®é›†ä¸‹è½½å¤±è´¥

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

æ›´å¤šé—®é¢˜è§£å†³ï¼š[archived/docs/DELEGATE_PROMPT.md](archived/docs/DELEGATE_PROMPT.md)

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- **[GENERATE_README.md](GENERATE_README.md)** - ç”Ÿæˆè„šæœ¬è¯¦ç»†è¯´æ˜ï¼ˆå¿…è¯»ï¼‰
- **[archived/docs/](archived/docs/)** - å®Œæ•´æŠ€æœ¯æ–‡æ¡£
  - [QUICKSTART.md](archived/docs/QUICKSTART.md) - å¿«é€Ÿå¼€å§‹
  - [README_FLEXATTENTION.md](archived/docs/README_FLEXATTENTION.md) - FlexAttentionæ¦‚è¿°
  - [ARCHITECTURE.md](archived/docs/ARCHITECTURE.md) - æ¶æ„å›¾è¡¨
  - [å®ç°æ€»ç»“.md](archived/docs/å®ç°æ€»ç»“.md) - ä¸­æ–‡å®ç°æ€»ç»“

## ğŸ”— ç›¸å…³å·¥å…·ï¼ˆå·²å½’æ¡£ï¼‰

æµ‹è¯•ã€åˆ†æå’Œè°ƒè¯•å·¥å…·å·²ç§»è‡³`archived/`ç›®å½•ï¼š

- **è°ƒè¯•å·¥å…·**: `archived/tools/debug_flexattention.py`
- **æµ‹è¯•è„šæœ¬**: `archived/tests/`
- **åˆ†æå·¥å…·**: `archived/analysis/`
- **å¯è§†åŒ–**: `archived/plot/`
- **ç¤ºä¾‹**: `archived/examples/`

è¿™äº›å·¥å…·ä»å¯ä½¿ç”¨ï¼Œä½†ä¸æ˜¯è¿è¡Œç”Ÿæˆè„šæœ¬çš„å¿…éœ€é¡¹ã€‚

---

**æœ€åæ›´æ–°**: 2025-12-17

**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª | ğŸ“– å·²æ–‡æ¡£åŒ– | ğŸ§¹ å·²æ•´ç†
