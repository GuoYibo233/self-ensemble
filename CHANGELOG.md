# Changelog - Mask Matrix and FlexAttention Improvements

æœ¬æ–‡æ¡£è®°å½•æ¯æ¬¡æäº¤çš„è¯¦ç»†å˜æ›´å†…å®¹ / This document tracks detailed changes for each commit

---

## Commit 16164ef - Update documentation for max_samples and analysis tools
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `README.md` - æ·»åŠ æ–°åŠŸèƒ½ä½¿ç”¨è¯´æ˜
- âœ… `docs/QUICK_REFERENCE.md` - æ›´æ–°APIå‚è€ƒ

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### README.md
**æ–°å¢å†…å®¹**:
- æ·»åŠ  `--max_samples` å‚æ•°ä½¿ç”¨ç¤ºä¾‹
- æ·»åŠ Analysiså·¥å…·ä½¿ç”¨è¯´æ˜ï¼ˆå‘½ä»¤è¡Œå’ŒJupyterï¼‰
- æ›´æ–°æ–‡æ¡£ç´¢å¼•ï¼ŒåŒ…å« `FLEXATTENTION_USAGE.md` å’Œ `IMPROVEMENTS_SUMMARY.md`
- æ›´æ–°ä»“åº“ç»“æ„å›¾ï¼Œæ·»åŠ  `analysis/` ç›®å½•
- æ›´æ–°æœ€åä¿®æ”¹æ—¥æœŸä¸º 2025-10-13

**ç¤ºä¾‹ä»£ç **:
```bash
# é™åˆ¶ç”Ÿæˆæ ·æœ¬æ•°
python3 flex_attention_generate.py --max_samples 100

# åˆ†æç»“æœ
python3 analysis/analyze_flexattention.py --dataset webqa --model llama3.2_3b_it
```

#### docs/QUICK_REFERENCE.md
**æ–°å¢å†…å®¹**:
- æ·»åŠ  `--max_samples` å‚æ•°è¯´æ˜
- æ·»åŠ analysiså‘½ä»¤ç¤ºä¾‹
- æ·»åŠ æŒ‡å‘ `FLEXATTENTION_USAGE.md` çš„é“¾æ¥

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–‡æ¡£æ›´æ–°** - æ‰€æœ‰æ–‡æ¡£ä¸ä»£ç åŒæ­¥
- ğŸŸ¢ **å‘åå…¼å®¹** - ä¸å½±å“ç°æœ‰åŠŸèƒ½

---

## Commit 98cb294 - Add max_samples parameter and FlexAttention analysis tools
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `flex_attention_generate.py` - æ·»åŠ  `--max_samples` å‚æ•°
- âœ… `analysis/analyze_flexattention.py` - æ–°æ–‡ä»¶
- âœ… `analysis/flexattention_analysis.ipynb` - æ–°æ–‡ä»¶
- âœ… `FLEXATTENTION_USAGE.md` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### flex_attention_generate.py
**æ–°å¢åŠŸèƒ½**:
1. æ·»åŠ å‘½ä»¤è¡Œå‚æ•° `--max_samples`ï¼ˆç¬¬429-432è¡Œï¼‰
2. æ·»åŠ æ ·æœ¬è®¡æ•°é€»è¾‘ï¼ˆç¬¬512è¡Œï¼‰
3. æ·»åŠ è¾¾åˆ°é™åˆ¶æ—¶çš„åœæ­¢é€»è¾‘ï¼ˆç¬¬560-563è¡Œï¼‰

**ä»£ç å˜æ›´**:
```python
# æ–°å¢å‚æ•°
parser.add_argument(
    "--max_samples", type=int, default=None,
    help="Maximum number of samples to generate (default: None, process all)"
)

# æ–°å¢é™åˆ¶æ£€æŸ¥
sample_count += len(uuids)
if args.max_samples and sample_count >= args.max_samples:
    print(f"Reached max_samples limit ({args.max_samples}), stopping generation")
    break
```

#### analysis/analyze_flexattention.py (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: å‘½ä»¤è¡Œåˆ†æå·¥å…·ï¼ˆ207è¡Œä»£ç ï¼‰

**ä¸»è¦ç‰¹æ€§**:
- è®¡ç®—FlexAttentionå‡†ç¡®ç‡
- ä¸ä¼ ç»Ÿensembleæ–¹æ³•å¯¹æ¯”ï¼ˆavg, max, weighted_avg, weighted_maxï¼‰
- æ˜¾ç¤ºæ ·æœ¬ç”Ÿæˆç»“æœ
- åˆ†æä¸åŒparaphraseæ•°é‡çš„å½±å“

**ä½¿ç”¨æ–¹æ³•**:
```bash
python analysis/analyze_flexattention.py --dataset myriadlama --model qwen2.5_7b_it
python analysis/analyze_flexattention.py --dataset myriadlama --model qwen2.5_7b_it --compare_all
```

#### analysis/flexattention_analysis.ipynb (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: äº¤äº’å¼Jupyteråˆ†ænotebookï¼ˆ414è¡Œä»£ç ï¼‰

**ä¸»è¦åŠŸèƒ½**:
- æ•°æ®åŠ è½½å’Œæ¢ç´¢
- å¯è§†åŒ–å¯¹æ¯”ï¼ˆæ¡å½¢å›¾ã€æŠ˜çº¿å›¾ï¼‰
- é”™è¯¯åˆ†æ
- ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”

#### FLEXATTENTION_USAGE.md (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: å®Œæ•´ä½¿ç”¨æŒ‡å—ï¼ˆ252è¡Œæ–‡æ¡£ï¼‰

**åŒ…å«å†…å®¹**:
- å®Œæ•´å·¥ä½œæµç¤ºä¾‹
- å‚æ•°è¯´æ˜
- æœ€ä½³å®è·µ
- æ•…éšœæ’é™¤æŒ‡å—

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–°åŠŸèƒ½** - å¯ä»¥é™åˆ¶ç”Ÿæˆæ ·æœ¬æ•°é‡
- ğŸŸ¢ **æ–°å·¥å…·** - å®Œæ•´çš„åˆ†æå·¥å…·é“¾
- ğŸŸ¢ **å‘åå…¼å®¹** - `--max_samples` æ˜¯å¯é€‰å‚æ•°

---

## Commit b435757 - Fix separator display in segment output
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `tools/debug_flexattention.py` - ä¿®å¤separatoræ˜¾ç¤º
- âœ… `test_separator_fix.py` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### tools/debug_flexattention.py
**é—®é¢˜**: "Full Sequence with Segment Markers"è¾“å‡ºä¸­ï¼Œ[SEP]è¢«segmentè¾¹ç•Œåˆ‡å‰²

**ä¿®å¤**:
- æ¯ä¸ªsegmentç°åœ¨åŒ…å«å…¶åçš„separator tokens
- é€šè¿‡æ‰©å±•èŒƒå›´åˆ°ä¸‹ä¸€ä¸ªsegmentçš„startä½ç½®å®ç°

**ä»£ç é€»è¾‘**:
```python
# ä¹‹å‰: åªæ˜¾ç¤º segment.start åˆ° segment.end
# ç°åœ¨: æ˜¾ç¤º segment.start åˆ° next_segment.startï¼ˆåŒ…å«separatorï¼‰
```

#### test_separator_fix.py (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: éªŒè¯separatorä¿®å¤çš„æµ‹è¯•è„šæœ¬

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **Bugä¿®å¤** - [SEP]ç°åœ¨å®Œæ•´æ˜¾ç¤º
- ğŸŸ¢ **è°ƒè¯•æ”¹è¿›** - è¾“å‡ºæ›´æ¸…æ™°æ˜“è¯»

---

## Commit 20d2b67 - Add comprehensive README for all changes
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `CHANGES_README.md` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### CHANGES_README.md (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: å¿«é€Ÿå…¥é—¨æŒ‡å—ï¼ˆ163è¡Œæ–‡æ¡£ï¼‰

**åŒ…å«å†…å®¹**:
- æ‰€æœ‰æ”¹è¿›çš„å¿«é€Ÿæ¦‚è§ˆ
- ä½¿ç”¨ç¤ºä¾‹
- éªŒè¯å‘½ä»¤
- æŠ€æœ¯ç‰¹ç‚¹è¯´æ˜

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–‡æ¡£æ”¹è¿›** - æä¾›å¿«é€Ÿå…¥é—¨æŒ‡å—

---

## Commit 520423e - Add detailed before/after comparison document
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `BEFORE_AFTER_COMPARISON.md` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### BEFORE_AFTER_COMPARISON.md (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: å¯è§†åŒ–å¯¹æ¯”æ–‡æ¡£ï¼ˆ247è¡Œæ–‡æ¡£ï¼‰

**åŒ…å«å†…å®¹**:
- Mask matrixæ”¹è¿›çš„å‰åå¯¹æ¯”
- Promptæ ¼å¼æ”¹è¿›çš„å‰åå¯¹æ¯”
- å¯è§†åŒ–ç¤ºä¾‹
- è¯¦ç»†çš„æ”¹è¿›è¯´æ˜

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–‡æ¡£æ”¹è¿›** - æ¸…æ™°å±•ç¤ºæ”¹è¿›æ•ˆæœ

---

## Commit f391d86 - Add comprehensive documentation for improvements
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `IMPROVEMENTS_SUMMARY.md` - æ–°æ–‡ä»¶
- âœ… `test_output.txt` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### IMPROVEMENTS_SUMMARY.md (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: è¯¦ç»†æŠ€æœ¯æ–‡æ¡£ï¼ˆåŒ…å«å®Œæ•´çš„æŠ€æœ¯å®ç°è¯´æ˜ï¼‰

**åŒ…å«å†…å®¹**:
- æ™ºèƒ½é‡‡æ ·ç®—æ³•è¯¦è§£
- Separatoræ ¼å¼æ”¹è¿›è¯´æ˜
- æŠ€æœ¯å®ç°ç»†èŠ‚
- ä»£ç ç¤ºä¾‹

#### test_output.txt (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: æµ‹è¯•è¾“å‡ºç¤ºä¾‹

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–‡æ¡£æ”¹è¿›** - æä¾›è¯¦ç»†æŠ€æœ¯æ–‡æ¡£

---

## Commit 91905ff - Improve mask matrix visualization and prompt formatting
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `flex_attention_generate.py` - æ›´æ–°é»˜è®¤separator
- âœ… `tools/debug_flexattention.py` - å¢å¼ºå¯è§†åŒ–
- âœ… `tools/example_flexattention.py` - æ›´æ–°ç¤ºä¾‹
- âœ… `test_mask_visualization.py` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### flex_attention_generate.py
**æ”¹åŠ¨**: æ›´æ–°é»˜è®¤separator
- ä» ` [SEP] ` æ”¹ä¸º `\n\n[SEP]\n\n`
- æ”¹å–„promptè¾¹ç•Œçš„è§†è§‰åˆ†éš”

**ä»£ç å˜æ›´**:
```python
# ä¹‹å‰
separator=" [SEP] "

# ç°åœ¨
separator="\n\n[SEP]\n\n"
```

#### tools/debug_flexattention.py
**æ–°å¢åŠŸèƒ½**:
1. æ™ºèƒ½é‡‡æ ·ç®—æ³• - æ˜¾ç¤º~25ä¸ªå…³é”®ä½ç½®
2. Segmentæ ‡è®°ï¼ˆS#/E#/G0ï¼‰
3. æ›´å¥½çš„ç¬¦å·ï¼ˆâ– /Â·ä»£æ›¿âœ“/âœ—ï¼‰
4. å®Œæ•´çš„attentionç»“æ„å¯è§†åŒ–

**æ”¹è¿›ç»†èŠ‚**:
- ä¼˜å…ˆæ˜¾ç¤ºæ‰€æœ‰segmentè¾¹ç•Œ
- åœ¨æ¯ä¸ªsegmentå†…é‡‡æ ·ä»£è¡¨æ€§ä½ç½®
- æ˜¾ç¤ºgenerationèµ·å§‹ä½ç½®
- å¯¹å¤§å‹åºåˆ—ï¼ˆ248+ tokensï¼‰ä¿æŒå¯è¯»æ€§

#### tools/example_flexattention.py
**æ”¹åŠ¨**: æ›´æ–°å¯è§†åŒ–å‡½æ•°ä»¥ä½¿ç”¨æ–°çš„æ™ºèƒ½é‡‡æ ·

#### test_mask_visualization.py (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: å®Œæ•´æµ‹è¯•è„šæœ¬ï¼ˆæ— éœ€æ¨¡å‹ï¼‰

**æµ‹è¯•å†…å®¹**:
- éªŒè¯æ™ºèƒ½é‡‡æ ·ç®—æ³•
- æµ‹è¯•248-tokenåºåˆ—çš„å¯è§†åŒ–
- éªŒè¯segmentè¾¹ç•Œæ ‡è®°

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **ä¸»è¦æ”¹è¿›** - Mask matrixå¯è§†åŒ–å¤§å¹…æ”¹å–„
- ğŸŸ¢ **å¯è¯»æ€§æå‡** - Promptæ ¼å¼æ›´æ¸…æ™°
- ğŸŸ¢ **å‘åå…¼å®¹** - ä¸å½±å“ç”Ÿæˆé€»è¾‘

---

## æ€»ç»“ / Summary

### æ‰€æœ‰å˜æ›´çš„æ–‡ä»¶ç»Ÿè®¡
**ä¿®æ”¹çš„æ ¸å¿ƒæ–‡ä»¶**: 3
- `flex_attention_generate.py`
- `tools/debug_flexattention.py`
- `tools/example_flexattention.py`

**æ–°å¢çš„æ–‡ä»¶**: 9
- `test_mask_visualization.py`
- `test_separator_fix.py`
- `analysis/analyze_flexattention.py`
- `analysis/flexattention_analysis.ipynb`
- `IMPROVEMENTS_SUMMARY.md`
- `BEFORE_AFTER_COMPARISON.md`
- `CHANGES_README.md`
- `FLEXATTENTION_USAGE.md`
- `test_output.txt`

**æ›´æ–°çš„æ–‡æ¡£**: 2
- `README.md`
- `docs/QUICK_REFERENCE.md`

### åŠŸèƒ½ç»Ÿè®¡
- âœ… **6ä¸ªä¸»è¦åŠŸèƒ½æ”¹è¿›**
- âœ… **2ä¸ªBugä¿®å¤**
- âœ… **9ä¸ªæ–°æ–‡ä»¶**
- âœ… **5ä¸ªæ–‡æ¡£æ›´æ–°**
- âœ… **100%å‘åå…¼å®¹**

### ä»£ç è¡Œæ•°ç»Ÿè®¡
- **æ–°å¢ä»£ç **: ~1000è¡Œ
- **æ–°å¢æ–‡æ¡£**: ~1500è¡Œ
- **ä¿®æ”¹ä»£ç **: ~20è¡Œ

---

## Commit d09c197 - Add comprehensive CHANGELOG.md for tracking all changes
**æäº¤æ—¶é—´ / Date**: 2025-10-13

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `CHANGELOG.md` - æ–°æ–‡ä»¶

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### CHANGELOG.md (æ–°æ–‡ä»¶)
**åŠŸèƒ½**: è¯¦ç»†çš„å˜æ›´è¿½è¸ªæ–‡æ¡£ï¼ˆ311è¡Œæ–‡æ¡£ï¼‰

**åŒ…å«å†…å®¹**:
- æ¯ä¸ªcommitçš„è¯¦ç»†å˜æ›´è®°å½•
- æ–‡ä»¶çº§åˆ«çš„ä¿®æ”¹è¯´æ˜
- å…·ä½“ä»£ç ä¿®æ”¹å’Œç¤ºä¾‹
- å½±å“èŒƒå›´åˆ†æ
- ç»Ÿè®¡ä¿¡æ¯æ±‡æ€»

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ–‡æ¡£æ”¹è¿›** - æä¾›å®Œæ•´çš„å˜æ›´å†å²è¿½è¸ª

---

## å¾…æäº¤ - Improve error handling and diagnostics for FlexAttention
**æäº¤æ—¶é—´ / Date**: 2025-10-13 (Pending)

### æ–‡ä»¶å˜æ›´ / Files Changed
- âœ… `flex_attention_generate.py` - æ”¹è¿›é”™è¯¯å¤„ç†
- âœ… `CHANGELOG.md` - æ›´æ–°å˜æ›´è®°å½•å’Œæ•…éšœæ’é™¤

### å…·ä½“æ”¹åŠ¨ / Specific Changes

#### flex_attention_generate.py
**æ”¹è¿›**: å¢å¼ºé”™è¯¯è¯Šæ–­ä¿¡æ¯

**é—®é¢˜**: å½“FlexAttentionå¤±è´¥æ—¶ï¼Œåªæ˜¾ç¤ºç®€å•é”™è¯¯æ¶ˆæ¯ï¼Œéš¾ä»¥è¯Šæ–­é—®é¢˜

**ä¿®å¤**:
1. æ·»åŠ å®Œæ•´çš„tracebackè¾“å‡º
2. æ˜¾ç¤ºå¼‚å¸¸ç±»å‹å’Œè¯¦ç»†ä¿¡æ¯
3. åœ¨ç¬¬ä¸€æ¬¡é”™è¯¯æ—¶æ˜¾ç¤ºå®Œæ•´å †æ ˆè·Ÿè¸ª
4. æ”¹è¿›fallbackæç¤ºä¿¡æ¯

**ä»£ç å˜æ›´**:
```python
# ä¹‹å‰
except Exception as e:
    print(f"âš ï¸  Generation step {step} failed: {e}")

# ç°åœ¨
except Exception as e:
    import traceback
    print(f"âš ï¸  Generation step {step} failed: {type(e).__name__}: {e}")
    print(f"    Full error traceback:")
    traceback.print_exc()
    print(f"    Falling back to unpatched model...")
```

### æ•…éšœæ’é™¤æŒ‡å— / Troubleshooting Guide

#### é—®é¢˜: "Generation step [xx] failed: FlexAttentionWrapper.create_patched_forward"

**å¸¸è§åŸå› **:

1. **PyTorchç‰ˆæœ¬ä¸æ”¯æŒFlexAttention**
   - FlexAttentionéœ€è¦PyTorch 2.5+æˆ–nightlyç‰ˆæœ¬
   - æ£€æŸ¥: `python -c "import torch; print(torch.__version__)"`
   - è§£å†³: 
     ```bash
     pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121
     ```

2. **æ¨¡å‹æ¶æ„ä¸å…¼å®¹**
   - æŸäº›æ¨¡å‹çš„attentionå±‚ç»“æ„å¯èƒ½ä¸patchingä¸å…¼å®¹
   - æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰`q_proj`, `k_proj`, `v_proj`, `o_proj`
   - è§£å†³: ä½¿ç”¨ä¼ ç»Ÿensembleæ–¹æ³•
     ```bash
     python generate.py --dataset webqa --method avg --num_ensemble 5
     ```

3. **CUDA/è®¾å¤‡é—®é¢˜**
   - FlexAttentionå¯èƒ½å¯¹æŸäº›CUDAç‰ˆæœ¬æœ‰è¦æ±‚
   - æ£€æŸ¥: `python -c "import torch; print(torch.cuda.is_available())"`
   - è§£å†³: å°è¯•CPUæ¨¡å¼æˆ–æ›´æ–°CUDAé©±åŠ¨

4. **åºåˆ—é•¿åº¦é—®é¢˜**
   - éå¸¸é•¿çš„åºåˆ—å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³
   - è§£å†³: å‡å°‘paraphraseæ•°é‡æˆ–ä½¿ç”¨`--max_samples`é™åˆ¶

**è°ƒè¯•æ­¥éª¤**:

1. **è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯**
   ```bash
   python flex_attention_generate.py --dataset webqa --model llama3.2_3b_it \
       --num_paraphrases 5 --max_samples 10 2>&1 | tee debug.log
   ```

2. **éªŒè¯FlexAttentionå¯ç”¨æ€§**
   ```bash
   python -c "from torch.nn.attention.flex_attention import flex_attention; print('Available')"
   ```

3. **æµ‹è¯•ç®€å•æƒ…å†µ**
   ```bash
   # åªç”Ÿæˆ1ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
   python flex_attention_generate.py --dataset webqa --model llama3.2_3b_it \
       --num_paraphrases 3 --max_samples 1
   ```

4. **ä½¿ç”¨fallbackæœºåˆ¶**
   - ä»£ç ä¼šè‡ªåŠ¨fallbackåˆ°æ ‡å‡†attention
   - å¦‚æœfallbackæ­£å¸¸å·¥ä½œï¼Œè¯´æ˜é—®é¢˜åœ¨FlexAttentionæœ¬èº«

**ä¸´æ—¶è§£å†³æ–¹æ¡ˆ**:
å¦‚æœFlexAttentionæŒç»­å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿensembleæ–¹æ³•ï¼š
```bash
python generate.py --dataset webqa --model llama3.2_3b_it --method avg --num_ensemble 5
```

### å½±å“èŒƒå›´ / Impact
- ğŸŸ¢ **æ”¹è¿›** - æ›´å¥½çš„é”™è¯¯è¯Šæ–­
- ğŸŸ¢ **è°ƒè¯•** - å®Œæ•´çš„tracebackå¸®åŠ©å®šä½é—®é¢˜
- ğŸŸ¢ **ç”¨æˆ·ä½“éªŒ** - æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆ

---

*æ­¤æ–‡æ¡£ä¼šåœ¨æ¯æ¬¡æäº¤åæ›´æ–° / This document is updated with each commit*
