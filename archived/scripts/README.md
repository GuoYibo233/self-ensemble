# Baseline Generation Scripts

è¿™ä¸ªç›®å½•åŒ…å«ç”¨äºæ‰¹é‡ç”Ÿæˆbaselineçš„è„šæœ¬ã€‚

## ğŸ“ è„šæœ¬è¯´æ˜

### 1. `generate_all_baselines.sh` - Bashè„šæœ¬ç‰ˆæœ¬

ç®€å•çš„bashè„šæœ¬ï¼Œè‡ªåŠ¨æ‰«ææ‰€æœ‰å·²æœ‰æ¨¡å‹å¹¶ç”Ÿæˆbaselineã€‚

**ç‰¹ç‚¹**:
- âœ… ç®€å•æ˜“ç”¨
- âœ… è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„baseline
- âœ… å½©è‰²è¾“å‡º
- âœ… å®Œæ•´çš„ç»Ÿè®¡ä¿¡æ¯

**ç”¨æ³•**:
```bash
# åŸºæœ¬ç”¨æ³•ï¼ˆæ‰«æå¹¶ç”Ÿæˆæ‰€æœ‰ç¼ºå¤±çš„baselineï¼‰
bash scripts/generate_all_baselines.sh

# Dry runï¼ˆæŸ¥çœ‹ä¼šåšä»€ä¹ˆï¼Œä¸å®é™…æ‰§è¡Œï¼‰
bash scripts/generate_all_baselines.sh --dry-run

# å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰baseline
bash scripts/generate_all_baselines.sh --rewrite
```

### 2. `generate_all_baselines.py` - Pythonè„šæœ¬ç‰ˆæœ¬

åŠŸèƒ½æ›´å¼ºå¤§çš„Pythonç‰ˆæœ¬ï¼Œæ”¯æŒæ›´å¤šé€‰é¡¹ã€‚

**ç‰¹ç‚¹**:
- âœ… è‡ªåŠ¨æ‰«æå’Œæ£€æµ‹
- âœ… æ˜¾ç¤ºå·²æœ‰baselineçŠ¶æ€
- âœ… æ”¯æŒé€‰æ‹©ç‰¹å®šæ•°æ®é›†
- âœ… äº¤äº’å¼ç¡®è®¤
- âœ… è¯¦ç»†çš„è¿›åº¦æ˜¾ç¤º
- ğŸš§ æœªæ¥æ”¯æŒå¹¶è¡Œæ‰§è¡Œ

**ç”¨æ³•**:
```bash
# åŸºæœ¬ç”¨æ³•
python scripts/generate_all_baselines.py

# Dry run
python scripts/generate_all_baselines.py --dry-run

# åªå¤„ç†WebQA
python scripts/generate_all_baselines.py --dataset webqa

# å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
python scripts/generate_all_baselines.py --rewrite

# æŒ‡å®šæ•°æ®é›†æ ¹ç›®å½•
python scripts/generate_all_baselines.py --dataset-root /path/to/datasets
```

## ğŸ¯ å·¥ä½œæµç¨‹

### æ­¥éª¤1: æŸ¥çœ‹ç°æœ‰æ¨¡å‹

```bash
# ä½¿ç”¨bashè„šæœ¬dry run
bash scripts/generate_all_baselines.sh --dry-run

# æˆ–ä½¿ç”¨Pythonè„šæœ¬
python scripts/generate_all_baselines.py --dry-run
```

**è¾“å‡ºç¤ºä¾‹**:
```
======================================================================
Scanning for Existing Models
======================================================================

WEBQA:
  - llama3.2_1b              [originâœ— per_promptâœ—]
  - llama3.2_1b_it          [originâœ— per_promptâœ—]
  - llama3.2_3b              [originâœ— per_promptâœ—]
  - llama3.2_3b_it          [originâœ“ per_promptâœ“]  <- å·²æœ‰baseline
  - qwen2.5_3b_it           [originâœ— per_promptâœ—]
  - qwen2.5_7b_it           [originâœ— per_promptâœ—]
  - qwen3_1.7b               [originâœ— per_promptâœ—]
  - qwen3_4b                 [originâœ— per_promptâœ—]
  - qwen3_8b                 [originâœ— per_promptâœ—]

MYRIADLAMA:
  - qwen1.5_moe_a2.7b_chat  [originâœ— per_promptâœ—]

Total models found: 10
Models to process: 9
```

### æ­¥éª¤2: ç”Ÿæˆæ‰€æœ‰baseline

```bash
# æ¨èï¼šä½¿ç”¨bashè„šæœ¬ï¼ˆæ›´ç¨³å®šï¼‰
bash scripts/generate_all_baselines.sh

# æˆ–ä½¿ç”¨Pythonè„šæœ¬
python scripts/generate_all_baselines.py
```

è„šæœ¬ä¼šï¼š
1. æ‰«ææ‰€æœ‰å·²æœ‰æ¨¡å‹ç›®å½•
2. æ£€æŸ¥å“ªäº›æ¨¡å‹ç¼ºå°‘baseline
3. é€ä¸ªç”Ÿæˆbaselineï¼ˆorigin + per_promptï¼‰
4. æ˜¾ç¤ºè¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯

### æ­¥éª¤3: æŸ¥çœ‹ç»“æœ

ç”Ÿæˆå®Œæˆåï¼Œæ¯ä¸ªæ¨¡å‹ç›®å½•ä¸‹ä¼šæœ‰ï¼š
```
/net/.../datasets/webqa/llama3.2_3b_it/
â”œâ”€â”€ paraphrases_dataset/
â”œâ”€â”€ baseline_origin.feather       # æ–°ç”Ÿæˆ
â””â”€â”€ baseline_per_prompt.feather   # æ–°ç”Ÿæˆ
```

## ğŸ“Š é¢„è®¡è¿è¡Œæ—¶é—´

å¯¹äºWebQAæ•°æ®é›†ï¼ˆ~1943ä¸ªé—®é¢˜ï¼‰ï¼š

| æ¨¡å‹ | Baseline 1 (origin) | Baseline 2 (per_prompt) | æ€»è®¡ |
|------|---------------------|-------------------------|------|
| llama3.2_3b_it | ~5-10åˆ†é’Ÿ | ~30-40åˆ†é’Ÿ | ~35-50åˆ†é’Ÿ |
| qwen2.5_7b_it | ~8-15åˆ†é’Ÿ | ~45-60åˆ†é’Ÿ | ~53-75åˆ†é’Ÿ |

**æ‰€æœ‰9ä¸ªæ¨¡å‹**: çº¦6-12å°æ—¶ï¼ˆé¡ºåºæ‰§è¡Œï¼‰

## ğŸ”§ é«˜çº§ç”¨æ³•

### åªé‡æ–°ç”Ÿæˆç‰¹å®šæ•°æ®é›†

```bash
# åªå¤„ç†WebQA
python scripts/generate_all_baselines.py --dataset webqa

# åªå¤„ç†MyriadLAMA
python scripts/generate_all_baselines.py --dataset myriadlama
```

### åœ¨tmuxä¸­åå°è¿è¡Œ

```bash
# åˆ›å»ºæ–°çš„tmux session
tmux new -s baseline_gen

# åœ¨tmuxä¸­è¿è¡Œè„šæœ¬
bash scripts/generate_all_baselines.sh

# æŒ‰ Ctrl+B ç„¶åæŒ‰ D åˆ†ç¦»session
# ç¨åé‡æ–°è¿æ¥: tmux attach -t baseline_gen
```

### ç›‘æ§è¿›åº¦

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§è¾“å‡ºæ–‡ä»¶ç”Ÿæˆ
watch -n 60 'ls -lh /net/tokyo100-10g/data/str01_01/y-guo/datasets/webqa/*/baseline_*.feather'

# æˆ–ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: æŸä¸ªæ¨¡å‹å¤±è´¥

**ç—‡çŠ¶**: è„šæœ¬åœ¨æŸä¸ªæ¨¡å‹å¤„å¤±è´¥å¹¶é€€å‡º

**è§£å†³**:
```bash
# è·³è¿‡å¤±è´¥çš„æ¨¡å‹ï¼Œæ‰‹åŠ¨ä¸ºå…¶ç”Ÿæˆbaseline
python baseline_generate.py --method all --dataset webqa --model å¤±è´¥çš„æ¨¡å‹å

# ç„¶åé‡æ–°è¿è¡Œè„šæœ¬ç»§ç»­å¤„ç†å…¶ä»–æ¨¡å‹
bash scripts/generate_all_baselines.sh
```

### é—®é¢˜2: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: CUDA out of memory

**è§£å†³**:
```bash
# å‡å°‘batch sizeï¼ˆéœ€è¦ä¿®æ”¹baseline_generate.pyä¸­çš„batch_sizeï¼‰
# æˆ–ä¸€æ¬¡åªç”Ÿæˆä¸€ä¸ªæ¨¡å‹
python baseline_generate.py --method all --dataset webqa --model llama3.2_3b_it
```

### é—®é¢˜3: ç£ç›˜ç©ºé—´ä¸è¶³

**ç—‡çŠ¶**: No space left on device

**è§£å†³**:
```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
df -h /net/tokyo100-10g/data/str01_01/y-guo/

# æ¸…ç†ä¸éœ€è¦çš„æ—§ç»“æœ
rm /net/.../datasets/webqa/old_model/*.feather
```

## ğŸ“ è„šæœ¬è¾“å‡ºç¤ºä¾‹

```
========================================================================
Generate Baselines for All Existing Models
========================================================================
Dataset root: /net/tokyo100-10g/data/str01_01/y-guo/datasets
Project root: /home/y-guo/self-ensemble/self-ensemble
Rewrite: false
Dry run: false

========================================================================
Scanning WebQA Models
========================================================================

--------------------------------------------------------------------
Dataset: webqa | Model: llama3.2_1b
--------------------------------------------------------------------
Executing: python3 baseline_generate.py --method all --dataset webqa --model llama3.2_1b

======================================================================
Baseline 1: Origin (Attention Mode Baseline)
======================================================================
Method: Uses only original questions (no paraphrases)
Output: .../baseline_origin.feather

Generating baseline (origin): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [05:23<00:00]

âœ… Baseline 1 (origin) results saved to: baseline_origin.feather
   Total samples: 1943

======================================================================
Baseline 2: Per-Prompt (Attention Mode Second Baseline)
======================================================================
...

âœ… Successfully generated baselines for webqa/llama3.2_1b

--------------------------------------------------------------------
Dataset: webqa | Model: llama3.2_3b
--------------------------------------------------------------------
...

========================================================================
Summary
========================================================================
Total models found: 10
Generated: 9
Skipped: 1
Done!
========================================================================
```

## ğŸ¯ ä¸‹ä¸€æ­¥

ç”Ÿæˆå®Œæ‰€æœ‰baselineåï¼š

1. **åˆ†æç»“æœ**:
   ```bash
   python analysis/analyze_baseline.py --dataset webqa --model llama3.2_3b_it
   ```

2. **å¯¹æ¯”æ‰€æœ‰æ¨¡å‹**:
   ```bash
   python analysis/compare_all_baselines.py
   ```

3. **ç”ŸæˆæŠ¥å‘Š**:
   ```bash
   python analysis/generate_baseline_report.py --output baseline_report.md
   ```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [BASELINE_USAGE.md](../BASELINE_USAGE.md) - Baselineä½¿ç”¨æŒ‡å—
- [baseline_generate.py](../baseline_generate.py) - å•ä¸ªæ¨¡å‹çš„baselineç”Ÿæˆè„šæœ¬
- [analyze_baseline.py](../analysis/analyze_baseline.py) - Baselineåˆ†æè„šæœ¬
