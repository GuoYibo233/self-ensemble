# FlexAttention Bug Fix Documentation Guide

## ğŸ“š æ–‡æ¡£æ¦‚è§ˆ / Documentation Overview

æœ¬ç›®å½•åŒ…å«FlexAttentionå®ç°è¿‡ç¨‹ä¸­çš„å®Œæ•´bugä¿®å¤æ–‡æ¡£ã€‚

This directory contains complete bug fix documentation for the FlexAttention implementation.

---

## ğŸ“ æ–‡æ¡£ç»“æ„ / Document Structure

### 1. **FLEXATTENTION_BUGFIX_LOG.md** 
ğŸ“‹ **è¯¦ç»†çš„Bugä¿®å¤æ—¥å¿— / Detailed Bug Fix Log**

- **ç”¨é€”**: å®Œæ•´è®°å½•4ä¸ªå…³é”®bugåŠå…¶ä¿®å¤
- **åŒ…å«å†…å®¹**:
  - é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
  - æ ¹æœ¬åŸå› åˆ†æ
  - ä¿®å¤å‰åä»£ç å¯¹æ¯”
  - æ–‡ä»¶ä½ç½®å’Œè¡Œå·
  - æµ‹è¯•éªŒè¯ç»“æœ

**ä½•æ—¶æŸ¥çœ‹**: éœ€è¦äº†è§£å…·ä½“bugç»†èŠ‚æˆ–è¿›è¡Œç±»ä¼¼è°ƒè¯•æ—¶

---

### 2. **GITHUB_COPILOT_REVIEW_PROMPT.md**
ğŸ¤– **GitHub Copilot ä»£ç å®¡æŸ¥æŒ‡å— / Code Review Prompt**

- **ç”¨é€”**: æŒ‡å¯¼GitHub Copilotè¿›è¡Œä»£ç å®¡æŸ¥
- **åŒ…å«å†…å®¹**:
  - ç»“æ„åŒ–çš„å®¡æŸ¥æ¸…å•
  - 4ä¸ªbugçš„éªŒè¯è¦ç‚¹
  - APIå…¼å®¹æ€§æ£€æŸ¥é¡¹
  - FlexAttentionæœ€ä½³å®è·µ
  - æ¨èçš„æµ‹è¯•ç”¨ä¾‹
  - è¾“å‡ºæ ¼å¼æ¨¡æ¿

**å¦‚ä½•ä½¿ç”¨**:
```bash
# å¤åˆ¶æ•´ä¸ªæ–‡æ¡£å†…å®¹ï¼Œç„¶ååœ¨GitHub Copilot Chatä¸­è¾“å…¥ï¼š
"Please review the code in flex_attention_generate.py following 
the instructions in this prompt."
```

---

### 3. **../CHANGELOG.md**
ğŸ“ **é¡¹ç›®å˜æ›´æ—¥å¿— / Project Changelog**

- **ä½ç½®**: `/self-ensemble/CHANGELOG.md`
- **ç”¨é€”**: æŒ‰æ—¶é—´é¡ºåºè®°å½•æ‰€æœ‰é‡è¦å˜æ›´
- **æœ€æ–°ç« èŠ‚**: "FlexAttention Bug Fixes Complete âœ…"

**ä½•æ—¶æŸ¥çœ‹**: éœ€è¦äº†è§£é¡¹ç›®æ¼”è¿›å†å²æˆ–æœ€æ–°å˜æ›´æ‘˜è¦

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯ / Use Cases

### åœºæ™¯1: é‡åˆ°ç±»ä¼¼Bug
1. æŸ¥çœ‹ **FLEXATTENTION_BUGFIX_LOG.md**
2. å¯¹ç…§é”™è¯¯ä¿¡æ¯æ‰¾åˆ°ç›¸åº”ç« èŠ‚
3. å‚è€ƒä¿®å¤æ–¹æ¡ˆ

### åœºæ™¯2: ä»£ç å®¡æŸ¥
1. ä½¿ç”¨ **GITHUB_COPILOT_REVIEW_PROMPT.md**
2. æŒ‰ç…§æ¸…å•é€é¡¹æ£€æŸ¥
3. å‚è€ƒæœ€ä½³å®è·µå»ºè®®

### åœºæ™¯3: äº†è§£é¡¹ç›®çŠ¶æ€
1. é˜…è¯» **CHANGELOG.md** æœ€æ–°ç« èŠ‚
2. æŸ¥çœ‹ä¿®å¤å‰åå¯¹æ¯”
3. äº†è§£æŠ€æœ¯è¦ç‚¹æ€»ç»“

### åœºæ™¯4: æ–°æˆå‘˜å…¥èŒ
1. å…ˆè¯» **CHANGELOG.md** äº†è§£æ•´ä½“
2. è¯¦è¯» **FLEXATTENTION_BUGFIX_LOG.md** äº†è§£æŠ€æœ¯ç»†èŠ‚
3. ä½¿ç”¨ **GITHUB_COPILOT_REVIEW_PROMPT.md** è¿›è¡Œä»£ç å­¦ä¹ 

---

## ğŸ”‘ å…³é”®æŠ€æœ¯è¦ç‚¹ / Key Technical Points

### 1. Transformers API å˜åŒ–
- `apply_rotary_pos_emb` åœ¨4.55.2ä¸­æ˜¯**æ¨¡å—çº§å‡½æ•°**è€Œéç±»æ–¹æ³•
- éœ€è¦ä» `transformers.models.llama.modeling_llama` å¯¼å…¥

### 2. FlexAttention Requirements
- `mask_mod` å‡½æ•°å¿…é¡»è¿”å› **Tensor** è€ŒéPython bool
- ä½¿ç”¨tensoræ¯”è¾ƒ (å¦‚ `q_idx >= 0`) è€Œéå­—é¢å€¼ (`True`)
- vmapè¦æ±‚æ‰€æœ‰è¿”å›å€¼éƒ½æ˜¯tensorç±»å‹

### 3. LLaMA GQA Architecture
- 24ä¸ªQuery heads
- 8ä¸ªKey/Value heads (Grouped Query Attention)
- Head dimension: 128
- éœ€è¦åœ¨FlexAttentionå‰æ‰©å±•KV heads

### 4. è·¯å¾„é…ç½®
- ä½¿ç”¨å½“å‰ç”¨æˆ·è·¯å¾„é¿å…æƒé™é—®é¢˜
- è¾“å‡ºç›®å½•: `/home/y-guo/self-ensemble/self-ensemble/datasets/`

---

## ğŸ§ª éªŒè¯æµ‹è¯• / Verification Tests

### å¿«é€Ÿæµ‹è¯•
```bash
cd /home/y-guo/self-ensemble/self-ensemble
python3 flex_attention_generate.py \
    --dataset webqa \
    --model llama3.2_3b_it \
    --max_samples 1
```

### æœŸæœ›è¾“å‡º
```
âœ… FlexAttention is available
âœ… Results saved to .../flex_attention-5.feather
```

### ä¸åº”å‡ºç°çš„è­¦å‘Š
```
âŒ "Falling back to unpatched model..."
âŒ "AttributeError: 'LlamaAttention' object has no attribute"
âŒ "ValueError: vmap(simple_mask_mod, ...): must only return Tensors"
âŒ "RuntimeError: Expected all tensors to be on the same device"
```

---

## ğŸ“Š ä¿®å¤ç»Ÿè®¡ / Fix Statistics

| Bugç±»å‹ | ä¸¥é‡ç¨‹åº¦ | ä¿®å¤éš¾åº¦ | æ ¹æœ¬åŸå›  |
|---------|---------|---------|----------|
| è¾“å‡ºç›®å½•æƒé™ | ğŸ”´ High | Easy | è·¯å¾„é…ç½®é”™è¯¯ |
| æ–¹æ³•ç»‘å®šé”™è¯¯ | ğŸŸ¡ Medium | Medium | Pythonç»‘å®šæœºåˆ¶è¯¯ç”¨ |
| APIå…¼å®¹æ€§ | ğŸ”´ High | Hard | Transformersç‰ˆæœ¬å˜åŒ– |
| è¿”å›ç±»å‹é”™è¯¯ | ğŸŸ¡ Medium | Easy | FlexAttention APIè¦æ±‚ |
| è®¾å¤‡ä¸åŒ¹é… | ğŸ”´ High | Easy | å¤šGPUç¯å¢ƒå¼ é‡è®¾å¤‡ç®¡ç† |

**æ€»è®¡**: 5ä¸ªbugå…¨éƒ¨ä¿®å¤ âœ…

---

## ğŸ”— ç›¸å…³æ–‡æ¡£ / Related Documents

- `FLEX_ATTENTION_IMPLEMENTATION.md` - FlexAttentionå®ç°æŒ‡å—
- `LINUX_SETUP.md` - Linuxç¯å¢ƒé…ç½®
- `QUICK_REFERENCE.md` - å¿«é€Ÿå‚è€ƒ
- `å®ç°æ€»ç»“.md` - ä¸­æ–‡æŠ€æœ¯æ€»ç»“

---

## ğŸ’¡ æœ€ä½³å®è·µ / Best Practices

### 1. æ–‡æ¡£ç»´æŠ¤
- âœ… æ¯æ¬¡bugä¿®å¤éƒ½è®°å½•åˆ°æ–‡æ¡£
- âœ… åŒ…å«é”™è¯¯ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆ
- âœ… æä¾›ä»£ç å¯¹æ¯”å’Œä½ç½®
- âœ… åŒè¯­æ”¯æŒä¸­è‹±æ–‡

### 2. ä»£ç å®¡æŸ¥
- âœ… ä½¿ç”¨ç»“æ„åŒ–çš„å®¡æŸ¥æ¸…å•
- âœ… å…³æ³¨APIå…¼å®¹æ€§å˜åŒ–
- âœ… éªŒè¯tensorå½¢çŠ¶å’Œç±»å‹
- âœ… æµ‹è¯•è¾¹ç•Œæƒ…å†µ

### 3. è°ƒè¯•æµç¨‹
- âœ… ä¿ç•™å®Œæ•´çš„é”™è¯¯å †æ ˆ
- âœ… è®°å½•è°ƒè¯•è¿‡ç¨‹å’Œå‘ç°
- âœ… éªŒè¯ä¿®å¤çš„æœ‰æ•ˆæ€§
- âœ… åˆ›å»ºå›å½’æµ‹è¯•

---

## ğŸ“ è”ç³»æ–¹å¼ / Contact

å¦‚æœ‰é—®é¢˜æˆ–å‘ç°æ–°çš„bugï¼Œè¯·ï¼š
1. æŸ¥é˜…ç°æœ‰æ–‡æ¡£å¯»æ‰¾è§£å†³æ–¹æ¡ˆ
2. åœ¨ç›¸åº”æ–‡æ¡£ä¸­æ·»åŠ æ–°çš„å‘ç°
3. æ›´æ–°CHANGELOGè®°å½•å˜æ›´

---

**æœ€åæ›´æ–°**: 2025-10-15
**çŠ¶æ€**: All 5 bugs fixed âœ…
**ç‰ˆæœ¬**: FlexAttention v1.1 (stable, multi-GPU compatible)
